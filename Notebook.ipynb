{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Texutal Similarity (STS) based text classification using Google's Universal Sentence Encoder implemented via TensorFlow-GPU, NVIDIA CUDA and cuDNN. \n",
    "\n",
    "Task: Find top 10 most semantically similar sentences for a given short sentence as query from a corpus of short, messy and unstructed english sentences.\n",
    "\n",
    "Tags: challenging text-classification, short unstructured and tangled texts, classification scenario with six thousand plus classes, GPU supported Transfer Learning (TL) approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import util\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "pd.set_option('display.max_colwidth', 1500)\n",
    "pd.set_option('display.max_rows', 3000)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "#set gpu memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set gpu memory limit\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9684\n"
     ]
    }
   ],
   "source": [
    "#text_dict = dict(zip(dfinal.filtered_text, dfinal.Expected))\n",
    "#print(len(text_dict))\n",
    "text_dict = pd.Series(dfinal.Expected.values,index=(dfinal.filtered_text+dfinal.random)).to_dict()\n",
    "print(len(text_dict))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---------------------------------SENTENCE ENCODER -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module universal-sentence-encoder-large_5 loaded\n"
     ]
    }
   ],
   "source": [
    "module_url = \"universal-sentence-encoder-large_5\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "\n",
    "def embed(input):\n",
    "  return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['Refined_Description'].to_list()\n",
    "corpus_embeddings = embed(corpus)\n",
    "corpus_embeddings = corpus_embeddings.numpy()\n",
    "corpus_embeddings = torch.from_numpy(corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "queries = text_dict\n",
    "hist_dict = {1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,10:0}\n",
    "\n",
    "# Find the closest 10 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 10\n",
    "i=0\n",
    "count = 0\n",
    "total_recall = 0\n",
    "real_recall = 0\n",
    "\n",
    "for query in queries:\n",
    "    inquery = [''.join([s for s in query if not s.isdigit()])]\n",
    "    query_embedding = embed(inquery)\n",
    "    query_embedding = query_embedding.numpy()\n",
    "    query_embedding = torch.from_numpy(query_embedding)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "    print(\"\\n\\n==========\"+str(i)+\"============\\n\\n\")\n",
    "    print(\"Query:\", inquery)\n",
    "    expected = queries[query]\n",
    "    print(\"\\nExpected:\",expected)\n",
    "    expected_string = re.sub('{.*$','',expected)\n",
    "    print(\"\\nTop 10 most similar sentences in corpus:\")\n",
    "    j = 0\n",
    "    match = 0\n",
    "    all_results=[]\n",
    "    for idx in top_results[0:top_k]:\n",
    "        j = j + 1\n",
    "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))\n",
    "        all_results.append(corpus[idx].strip())\n",
    "        if(corpus[idx].strip() == expected_string.strip()):\n",
    "            count = count + 1\n",
    "            match = match + 1\n",
    "            hist_dict[j]+=1\n",
    "    if (match>1):\n",
    "        extra_match = match - 1\n",
    "        count = count - extra_match\n",
    "    i=i+1\n",
    "    \n",
    "    #Recall total\n",
    "    recall_total = 0\n",
    "    print(expected)\n",
    "    expected_number = re.sub('\\D+','',expected)\n",
    "    expected_number_four = str(expected_number)[:4]\n",
    "    \n",
    "    for code in df['Code']:\n",
    "        if (int(str(expected_number)[:4]) == int(str(code)[:4])):\n",
    "            recall_total +=1\n",
    "            \n",
    "    #Recall relevant\n",
    "    dtemp = df[df['Code'].astype(str).str.startswith(expected_number_four)]\n",
    "    all_relevant_desc = dtemp['Refined_Description'].to_list()\n",
    "    recall_relevant = sum(desc in all_results for desc in all_relevant_desc)\n",
    "    \n",
    "    #Recall\n",
    "    recall = recall_relevant/recall_total\n",
    "    real_recall+=recall\n",
    "    if(recall==0.0):\n",
    "        recall=1.0\n",
    "    total_recall+=recall\n",
    "    print(\"\\n recall = \"+str(recall))\n",
    "    \n",
    "print(\"\\n\\n==========--------------------==========\\n\\n\")\n",
    "print(\"Sentence Encoder: \"+str(count+1)+\" out of \"+str(i))\n",
    "accuracy = float(((count+1)/i)*100)\n",
    "print(\"Accuracy: \"+str(accuracy))\n",
    "r_recall = float((real_recall/i)*100)\n",
    "print(\"Real Recall:\"+str(r_recall))\n",
    "t_recall = float((total_recall/i)*100)\n",
    "print(\"Total Recall:\"+str(t_recall))\n",
    "F1 = 2 * (accuracy * t_recall) / (accuracy + t_recall)\n",
    "print(\"F1 Score:\"+str(F1))\n",
    "print(\"\\n\\n==========--------------------==========\\n\\n\")\n",
    "print(hist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "width = 1.0 \n",
    "plt.bar(hist_dict.keys(), hist_dict.values(), width, color='#115ed9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE on TF-Hub: https://tfhub.dev/google/universal-sentence-encoder/1 \n",
    "Paper: Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-CÃ©spedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil. Universal Sentence Encoder. arXiv:1803.11175, 2018."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
